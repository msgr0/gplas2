Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	awk_links
	1	awk_nodes
	1	gplas_coocurr
	1	gplas_coverage
	1	gplas_paths
	1	mlplasmids
	6

[Mon Jun 13 14:16:46 2022]
Job 1: Extracting the nodes from the graph test/faecium_graph.gfa

[Mon Jun 13 14:16:46 2022]
Finished job 1.
1 of 6 steps (17%) done

[Mon Jun 13 14:16:46 2022]
Job 5: Extracting the links from the graph test/faecium_graph.gfa

[Mon Jun 13 14:16:46 2022]
Finished job 5.
2 of 6 steps (33%) done

[Mon Jun 13 14:16:46 2022]
Job 3: Running mlplasmids to obtain the plasmid prediction using the nodes extracted from the graph.

[Mon Jun 13 14:16:46 2022]
Error in rule mlplasmids:
    jobid: 3
    output: mlplasmids_prediction/installation_plasmid_prediction.tab
    log: logs/installation_normal_log_mlplasmids.txt, logs/installation_error_log_mlplasmids.txt (check log file(s) for error message)
    shell:
        
        pwd
        Rscript ../scripts/run_mlplasmids.R         gplas_input/installation_raw_nodes.fasta mlplasmids_prediction/installation_plasmid_prediction.tab 0.5 'Enterococcus faecium'         1>> logs/installation_normal_log_mlplasmids.txt 2>> logs/installation_error_log_mlplasmids.txt
        
        (exited with non-zero exit code)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/rodrigo/gplas/.snakemake/log/2022-06-13T141645.989430.snakemake.log
